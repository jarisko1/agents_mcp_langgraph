{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37f0dad",
   "metadata": {},
   "source": [
    "# Agent test notebook\n",
    "## TODO:\n",
    "- Validator structured output does not work\n",
    "\n",
    "## Progress\n",
    "- Planner finished\n",
    "- Assistant need to be adjusted\n",
    "- Replanner is probably needed as well\n",
    "- https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/plan-and-execute/plan-and-execute.ipynb\n",
    "## Issues:\n",
    "- Getting stuck on infinite loop with web search - improve with assisstant prompt\n",
    "- YouTube videos\n",
    "```\n",
    "Task ID: a1e91b78-d3d8-4675-bb8d-62741b4b68a6\n",
    "Question: In the video https://www.youtube.com/watch?v=L1vXCYZAYYM, what is the highest number of bird species to be on camera simultaneously?\n",
    "```\n",
    "- mp3 files\n",
    "```\n",
    "Task ID: 99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3\n",
    "Question: Hi, I'm making a pie but I could use some help with my shopping list. I have everything I need for the crust, but I'm not sure about the filling. I got the recipe from my friend Aditi, but she left it as a voice memo and the speaker on my phone is buzzing so I can't quite make out what she's saying. Could you please listen to the recipe and list all of the ingredients that my friend described? I only want the ingredients for the filling, as I have everything I need to make my favorite pie crust. I've attached the recipe as Strawberry pie.mp3.\n",
    "\n",
    "In your response, please only list the ingredients, not any measurements. So if the recipe calls for \"a pinch of salt\" or \"two cups of ripe strawberries\" the ingredients on the list would be \"salt\" and \"ripe strawberries\".\n",
    "\n",
    "Please format your response as a comma separated list of ingredients. Also, please alphabetize the ingredients.\n",
    "File Name: 99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3.mp3\n",
    "```\n",
    "- Azure Content Moderation tends to interfere\n",
    "## Resources\n",
    "- Instructions: https://huggingface.co/learn/agents-course/unit4/hands-on\n",
    "- Leaderboard and codes: https://huggingface.co/spaces/agents-course/Students_leaderboard\n",
    "    - 1 good example: https://huggingface.co/spaces/cellerson/AgentCourseFinalProject/tree/main\n",
    "- GitHub models: https://github.com/marketplace?type=models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd8c916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ee390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import TypedDict, Annotated, Union, Literal, Optional, Tuple, List, Any\n",
    "import base64\n",
    "import mimetypes\n",
    "import operator\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage\n",
    "from langchain_community.tools import Tool, DuckDuckGoSearchRun\n",
    "# from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_url = \"https://agents-course-unit4-scoring.hf.space\"\n",
    "questions_url = f\"{api_url}/questions\"\n",
    "random_question_url = f\"{api_url}/random-question\"\n",
    "files_url = f\"{api_url}/files\"\n",
    "submit_url = f\"{api_url}/submit\"\n",
    "\n",
    "def get_question(random: bool = True):\n",
    "    \"\"\"\n",
    "    Get a random question from the API.\n",
    "    Returns\n",
    "        - question text\n",
    "        - task id\n",
    "        - binary file (if any)\n",
    "        - file name (if any)\n",
    "    \"\"\"\n",
    "\n",
    "    if random:\n",
    "        used_url = random_question_url\n",
    "    else:\n",
    "        used_url = questions_url\n",
    "\n",
    "    question_data = requests.get(used_url, timeout=15)\n",
    "    question_data.raise_for_status()\n",
    "    questions_json = question_data.json()\n",
    "\n",
    "    # Create list if only 1 question was requested\n",
    "    if not isinstance(questions_json, list):\n",
    "        questions_json = [questions_json]\n",
    "\n",
    "    for question_json in questions_json:\n",
    "\n",
    "        question = question_json[\"question\"]\n",
    "        task_id = question_json[\"task_id\"]\n",
    "\n",
    "        file_name = question_json.get(\"file_name\", None)\n",
    "\n",
    "        if file_name:\n",
    "            file_url = f\"{files_url}/{task_id}\"\n",
    "            response = requests.get(file_url, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            with open(os.path.join(\"tmp\", file_name), \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "        yield (question, task_id, file_name)\n",
    "\n",
    "def read_file(file_name: str) -> Tuple[str, str | bytes]:\n",
    "    \"\"\"\n",
    "    Returns file content as a string\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = os.path.join(\"tmp\", file_name)\n",
    "\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "\n",
    "    # Images\n",
    "    if mime_type and mime_type.startswith(\"image/\"):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return \"image\", f.read()\n",
    "\n",
    "    extension = file_name.split(\".\")[-1]\n",
    "    if not extension:\n",
    "        extension = \"unknown\"\n",
    "\n",
    "    # Excel files\n",
    "    if extension in [\"xlsx\", \"xls\"]:\n",
    "\n",
    "        return extension, pd.read_excel(file_path).to_string()\n",
    "\n",
    "    # mp3 files\n",
    "    # TODO: transcribe the mp3 file here\n",
    "    if extension in [\"mp3\"]:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return extension, \"We cannot read mp3 files yet.\"\n",
    "\n",
    "    # Anything else\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return extension, f.read()\n",
    "\n",
    "def submit_answer(submission_data: dict):\n",
    "    \"\"\"\n",
    "    Submit the answers for checking.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(submit_url, json=submission_data, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        result_data = response.json()\n",
    "        final_status = (\n",
    "            # f\"Submission Successful!\\n\"\n",
    "            # f\"User: {result_data.get('username')}\\n\"\n",
    "            # f\"Overall Score: {result_data.get('score', 'N/A')}% \"\n",
    "            # f\"({result_data.get('correct_count', '?')}/{result_data.get('total_attempted', '?')} correct)\\n\"\n",
    "            # f\"Message: {result_data.get('message', 'No message received.')}\"\n",
    "            result_data.get('score', 'N/A')\n",
    "        )\n",
    "        return final_status\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        error_detail = f\"Server responded with status {e.response.status_code}.\"\n",
    "        try:\n",
    "            error_json = e.response.json()\n",
    "            error_detail += f\" Detail: {error_json.get('detail', e.response.text)}\"\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            error_detail += f\" Response: {e.response.text[:500]}\"\n",
    "        status_message = f\"Submission Failed: {error_detail}\"\n",
    "        return status_message\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        status_message = \"Submission Failed: The request timed out.\"\n",
    "        return status_message\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        status_message = f\"Submission Failed: Network error - {e}\"\n",
    "        return status_message\n",
    "\n",
    "    except Exception as e:\n",
    "        status_message = f\"An unexpected error occurred during submission: {e}\"\n",
    "        return status_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f45e6",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3a5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "assistant_model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=\"gpt-4.1-mini\",\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "validator_model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=\"gpt-4.1\",\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "planning_model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    # azure_deployment=\"o3-mini\",\n",
    "    azure_deployment=\"gpt-4.1\",\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "replanning_model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    # azure_deployment=\"o3-mini\",\n",
    "    azure_deployment=\"gpt-4.1\",\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f846e0e",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba73e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_text(query: str) -> str:\n",
    "#     \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
    "#     results = bm25_retriever.invoke(query)\n",
    "#     if results:\n",
    "#         return \"\\n\\n\".join([doc.page_content for doc in results[:3]])\n",
    "#     else:\n",
    "#         return \"No matching guest information found.\"\n",
    "\n",
    "# guest_info_tool = Tool(\n",
    "#     name=\"guest_info_retriever\",\n",
    "#     func=extract_text,\n",
    "#     description=\"Retrieves detailed information about gala guests based on their name or relation.\"\n",
    "# )\n",
    "\n",
    "### Search tool\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# search_wrapper = GoogleSerperAPIWrapper()\n",
    "\n",
    "# search_tool = Tool(\n",
    "#         name=\"search_tool\",\n",
    "#         func=search_wrapper.run,\n",
    "#         description=\"useful for when you need to ask with search\",\n",
    "#     )\n",
    "\n",
    "### Python tool\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "python_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    search_tool,\n",
    "    python_tool,\n",
    "]\n",
    "\n",
    "assistant_model = assistant_model.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc76fe",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9186bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskState(TypedDict):\n",
    "\n",
    "    # Input data\n",
    "    question: str\n",
    "    task_id: str\n",
    "    file_name: Optional[str]\n",
    "    file_type: Optional[str]\n",
    "    file_content: Optional[bytes]\n",
    "\n",
    "    # Output data\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    answer: str\n",
    "    assistant_messages: list[AnyMessage]\n",
    "    # Note: this has to be called exactly like this for Tools to work\n",
    "    # messages: Annotated[list[AnyMessage], add_messages]\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e6137",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddad9fe",
   "metadata": {},
   "source": [
    "### Planner\n",
    "- Starts the task processing\n",
    "- Creates plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4facb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )\n",
    "\n",
    "def planner(state: TaskState):\n",
    "    \"\"\"Creates step by step plan to finish defined task\"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    planner_prompt = \"\"\"For the given objective, come up with a simple step by step plan.\n",
    "    This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\n",
    "    The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\"\n",
    "\n",
    "    planner_messages = [\n",
    "        SystemMessage(content=planner_prompt),\n",
    "        HumanMessage(content=question),\n",
    "    ]\n",
    "\n",
    "    planning_model_structured = planning_model.with_structured_output(Plan)\n",
    "\n",
    "    plan = planning_model_structured.invoke(planner_messages)\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan.steps\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e59907",
   "metadata": {},
   "source": [
    "### Replanner\n",
    "- Adjusts plan based on already done steps\n",
    "- Decides when the plan is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316f22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Answer(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Answer, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def replanner(state: TaskState):\n",
    "    \"\"\"Updates plan based on work already done\"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    plan = state[\"plan\"]\n",
    "    task = plan[0]\n",
    "    past_steps = state[\"past_steps\"]\n",
    "\n",
    "    # Add last message from assistant or validator to past steps\n",
    "    last_message = state[\"assistant_messages\"][-1]\n",
    "    past_steps.append((task, last_message.content))\n",
    "\n",
    "    replanner_prompt = f\"\"\"For the given objective, come up with a simple step by step plan.\n",
    "    This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\n",
    "    The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "    Your objective was this:\n",
    "    {question}\n",
    "\n",
    "    Your original plan was this:\n",
    "    {plan}\n",
    "\n",
    "    You have currently done the follow steps:\n",
    "    {past_steps}\n",
    "\n",
    "    Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that.\n",
    "    Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\n",
    "    Answer has to be formatted as specified in the question.\n",
    "    Be very concise and output only the answer.\"\"\"\n",
    "\n",
    "    replanner_messages = [\n",
    "        SystemMessage(content=replanner_prompt),\n",
    "    ]\n",
    "\n",
    "    replanning_model_structured = replanning_model.with_structured_output(Act)\n",
    "\n",
    "    replan = replanning_model_structured.invoke(replanner_messages)\n",
    "\n",
    "    if isinstance(replan.action, Answer):\n",
    "        return {\n",
    "            \"answer\": replan.action.response,\n",
    "            \"assistant_messages\": [],\n",
    "            \"messages\": []\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"plan\": replan.action.steps,\n",
    "            \"answer\": \"\",\n",
    "            \"assistant_messages\": [],\n",
    "            \"messages\": []\n",
    "        }\n",
    "\n",
    "\n",
    "def answer_provided_condition(state: TaskState)  -> Literal[\"validator\", \"assistant\"]:\n",
    "\n",
    "    if \"answer\" in state and state[\"answer\"]:\n",
    "        return \"validator\"\n",
    "    else:\n",
    "        return \"assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99975349",
   "metadata": {},
   "source": [
    "### Assistant with tools\n",
    "- Can use tools\n",
    "- Executes next step in the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef7b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state: TaskState):\n",
    "\n",
    "    file_name = state['file_name']\n",
    "    file_type = state['file_type']\n",
    "    file_content = state['file_content']\n",
    "    tool_messages = state['messages']\n",
    "    assistant_messages = state['assistant_messages']\n",
    "    plan = state[\"plan\"]\n",
    "\n",
    "    print(f\">>>>> {assistant_messages=}\")\n",
    "\n",
    "    if len(tool_messages) > 0:\n",
    "        assistant_messages.extend(tool_messages)\n",
    "\n",
    "    print(f\"==== CALLING ASSISTANT with {len(assistant_messages)} messages in queue\")\n",
    "\n",
    "    if len(assistant_messages) == 0:\n",
    "\n",
    "        assistant_system_prompt = f\"\"\"\n",
    "        You are an AI assistant anwering complex questions.\n",
    "        Think step by step and answer following question.\n",
    "        When doing web search, be very specific and precise with your queries and specify all the details - language, year, etc.\n",
    "        Include all collected information into your response. \"\"\"\n",
    "\n",
    "        if file_name:\n",
    "\n",
    "            if file_type != \"image\":\n",
    "                assistant_system_prompt += f\"\"\"\n",
    "\n",
    "                You can use following information to answer the question:\n",
    "\n",
    "                {file_content}\n",
    "                \"\"\"\n",
    "\n",
    "                system_content = [{\"type\": \"text\", \"text\": assistant_system_prompt}]\n",
    "            else:\n",
    "                image_base64 = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "\n",
    "                system_content = [\n",
    "                    {\"type\": \"text\", \"text\": assistant_system_prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_base64}\",\n",
    "                        },\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "        else:\n",
    "            system_content = [{\"type\": \"text\", \"text\": assistant_system_prompt}]\n",
    "\n",
    "        system_message = SystemMessage(\n",
    "            content=system_content\n",
    "        )\n",
    "\n",
    "        plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "        task = plan[0]\n",
    "        task_formatted = f\"\"\"For the following plan:\n",
    "        {plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "\n",
    "        human_message = HumanMessage(content=task_formatted)\n",
    "\n",
    "        assistant_messages.append(system_message)\n",
    "        assistant_messages.append(human_message)\n",
    "\n",
    "    response = assistant_model.invoke(assistant_messages)\n",
    "    assistant_messages.append(response)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"assistant_messages\": assistant_messages\n",
    "    }\n",
    "\n",
    "\n",
    "def tools_or_replanner_condition(state: TaskState) -> Literal[\"tools\", \"replanner\"]:\n",
    "    \"\"\"\n",
    "    If last message in the state is a tool call, navigate to the tools node, otherwise to the validator node.\n",
    "    \"\"\"\n",
    "\n",
    "    tool_messages = state[\"messages\"]\n",
    "\n",
    "    if len(tool_messages) > 0:\n",
    "        tool_message = tool_messages[-1]\n",
    "    else:\n",
    "        return \"replanner\"\n",
    "\n",
    "    if hasattr(tool_message, \"tool_calls\") and len(tool_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "\n",
    "    return \"replanner\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc232d3",
   "metadata": {},
   "source": [
    "### Validator\n",
    "- TODO: structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26908f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerAccepted(BaseModel):\n",
    "    \"\"\"Final answer to the question\"\"\"\n",
    "\n",
    "    answer_accepted: bool = Field(\n",
    "        description=\"Flag if answer to the initial question was validated. \"\n",
    "            \"If all format and other prerequisites were fulfilled, return True. \"\n",
    "            \"Otherwise return false to get back to processing.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AnswerFeedback(BaseModel):\n",
    "    \"\"\"Feedback to the final answer to the question\"\"\"\n",
    "\n",
    "    answer_feedback: bool = Field(\n",
    "        description=\"In case of incorrect answer, provide explanation what need to be changed.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AnswerValidation(BaseModel):\n",
    "    \"\"\"Final answer to the question\"\"\"\n",
    "\n",
    "    answer_validation: Tuple[AnswerAccepted, AnswerFeedback] = Field(\n",
    "        description=\"Fill in AnswerAccepted with True, if you accept the answer provided. \"\n",
    "            \"In case the answer does not fulfill requirements, fill explanation to AnswerFeedback\"\n",
    "    )\n",
    "\n",
    "\n",
    "def validator(state: TaskState):\n",
    "\n",
    "    answer = state[\"answer\"]\n",
    "\n",
    "    prompt = f\"\"\"You are a format reviewer.\n",
    "    Your role is to check whether the assistant's answer matches exactly the required structure.\n",
    "    Except requirement directly in the question, the answer has to be short, concise and to the point.\n",
    "    It should contain only the requested information without additional words.\n",
    "    Focus only on formatting, not on verifying the facts or contents.\n",
    "    If the format does not match, briefly explain what should be adjusted.\n",
    "    If the format is correct, respond only with the word FINISHED.\n",
    "\n",
    "    The question:\n",
    "    {state[\"question\"]}\n",
    "\n",
    "    Assistant's answer:\n",
    "    {answer}\n",
    "    \"\"\"\n",
    "\n",
    "    structured_validator_model = validator_model.with_structured_output(AnswerValidation)\n",
    "\n",
    "    response = structured_validator_model.invoke([HumanMessage(prompt)])\n",
    "\n",
    "    if not response.answer_accepted:\n",
    "        answer = \"\"\n",
    "\n",
    "    print(f\"{response=}\")\n",
    "\n",
    "    return {\n",
    "        # \"past_steps\": [(\"Output format validation\", response.content)], # This will be done by replanner via assistant_messages\n",
    "        \"messages\": [],\n",
    "        \"past_steps\": (\"Answer validation\", response.answer_feedback),\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "def validator_approval_condition(\n",
    "    state: Union[list[AnyMessage], dict[str, Any], BaseModel],\n",
    ") -> Literal[\"replanner\", END]:\n",
    "    \"\"\"\n",
    "    If the last answer is not correct, let the assistant rework it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if answer stayed filled or if it was revoked and deleted\n",
    "    answer = state[\"answer\"]\n",
    "\n",
    "    if answer:\n",
    "        return END\n",
    "    return \"replanner\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170e6d6",
   "metadata": {},
   "source": [
    "## Graph definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3aec6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "task_graph = StateGraph(TaskState)\n",
    "\n",
    "# Add nodes\n",
    "task_graph.add_node(\"planner\", planner)\n",
    "task_graph.add_node(\"replanner\", replanner)\n",
    "task_graph.add_node(\"validator\", validator)\n",
    "task_graph.add_node(\"assistant\", assistant)\n",
    "task_graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges\n",
    "task_graph.add_edge(START, \"planner\")\n",
    "task_graph.add_edge(\"planner\", \"assistant\")\n",
    "task_graph.add_conditional_edges(\"assistant\", tools_or_replanner_condition, [\"tools\", \"replanner\"]) # Continue with tools or proceed to replanner\n",
    "task_graph.add_edge(\"tools\", \"assistant\")\n",
    "task_graph.add_conditional_edges(\"replanner\", answer_provided_condition, [\"validator\", \"assistant\"]) # Validate answer continue working\n",
    "task_graph.add_conditional_edges(\"validator\", validator_approval_condition, [\"replanner\", END]) # Go to END or back to assistant for rework\n",
    "\n",
    "compiled_graph = task_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f87b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, Image\n",
    "\n",
    "# display(Image(compiled_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a53f02",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d30664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: 8e867cd7-cff9-4e6c-867a-ff5ddc2550be\n",
      "Question: How many studio albums were published by Mercedes Sosa between 2000 and 2009 (included)? You can use the latest 2022 version of english wikipedia.\n",
      "File Name: No file\n",
      ">>>>> assistant_messages=[]\n",
      "==== CALLING ASSISTANT with 0 messages in queue\n",
      ">>>>> assistant_messages=[SystemMessage(content=[{'type': 'text', 'text': '\\n        You are an AI assistant anwering complex questions.\\n        Think step by step and answer following question.\\n        When doing web search, be very specific and precise with your queries and specify all the details - language, year, etc.\\n        Include all collected information into your response. '}], additional_kwargs={}, response_metadata={}), HumanMessage(content='For the following plan:\\n        1. Go to the English Wikipedia page for Mercedes Sosa.\\n2. Locate the discography section on the page.\\n3. Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive.\\n4. Count the number of studio albums identified in this time period.\\n5. Record the final count as the answer.\\n\\nYou are tasked with executing step 1, Go to the English Wikipedia page for Mercedes Sosa..', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DB8RjZRdXNLoj6ZvdcmWorsK', 'function': {'arguments': '{\"query\":\"Mercedes Sosa site:en.wikipedia.org\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 293, 'total_tokens': 318, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZCkoN3ulBg9xsBzjLTDxveE1wv', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--e35401c4-e4a8-43eb-92c1-db6f7cd682cb-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa site:en.wikipedia.org'}, 'id': 'call_DB8RjZRdXNLoj6ZvdcmWorsK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 25, 'total_tokens': 318, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==== CALLING ASSISTANT with 4 messages in queue\n",
      ">>>>> assistant_messages=[]\n",
      "==== CALLING ASSISTANT with 0 messages in queue\n",
      ">>>>> assistant_messages=[SystemMessage(content=[{'type': 'text', 'text': '\\n        You are an AI assistant anwering complex questions.\\n        Think step by step and answer following question.\\n        When doing web search, be very specific and precise with your queries and specify all the details - language, year, etc.\\n        Include all collected information into your response. '}], additional_kwargs={}, response_metadata={}), HumanMessage(content='For the following plan:\\n        1. Locate the discography section on the Mercedes Sosa Wikipedia page.\\n2. Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive.\\n3. Count the number of studio albums identified in this time period.\\n4. Record the final count as the answer.\\n\\nYou are tasked with executing step 1, Locate the discography section on the Mercedes Sosa Wikipedia page..', additional_kwargs={}, response_metadata={}), AIMessage(content='I will now locate the discography section on the Mercedes Sosa Wikipedia page.', additional_kwargs={'tool_calls': [{'id': 'call_zibHgLSxmLrkIoBzdrFgpSxW', 'function': {'arguments': '{\"query\":\"Mercedes Sosa Wikipedia page discography section\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 286, 'total_tokens': 329, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZFcpBa6E8G5ZfOMXrxWtcN7QwK', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--22e7003c-6fb7-402e-a228-4f7e9a842f4e-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa Wikipedia page discography section'}, 'id': 'call_zibHgLSxmLrkIoBzdrFgpSxW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 286, 'output_tokens': 43, 'total_tokens': 329, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==== CALLING ASSISTANT with 4 messages in queue\n",
      ">>>>> assistant_messages=[]\n",
      "==== CALLING ASSISTANT with 0 messages in queue\n",
      ">>>>> assistant_messages=[SystemMessage(content=[{'type': 'text', 'text': '\\n        You are an AI assistant anwering complex questions.\\n        Think step by step and answer following question.\\n        When doing web search, be very specific and precise with your queries and specify all the details - language, year, etc.\\n        Include all collected information into your response. '}], additional_kwargs={}, response_metadata={}), HumanMessage(content='For the following plan:\\n        1. Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive.\\n2. Count the number of studio albums identified in this time period.\\n3. Record the final count as the answer.\\n\\nYou are tasked with executing step 1, Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive..', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HHoUWbV1r4s5vNya2U3i3faN', 'function': {'arguments': '{\"query\":\"Mercedes Sosa studio albums 2000 to 2009\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 280, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZJp8g00nvsfJ6yR0ak9R3ldLZP', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--0f18280f-02df-4185-ba62-edee2d9d4698-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa studio albums 2000 to 2009'}, 'id': 'call_HHoUWbV1r4s5vNya2U3i3faN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 280, 'output_tokens': 29, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==== CALLING ASSISTANT with 4 messages in queue\n",
      ">>>>> assistant_messages=[SystemMessage(content=[{'type': 'text', 'text': '\\n        You are an AI assistant anwering complex questions.\\n        Think step by step and answer following question.\\n        When doing web search, be very specific and precise with your queries and specify all the details - language, year, etc.\\n        Include all collected information into your response. '}], additional_kwargs={}, response_metadata={}), HumanMessage(content='For the following plan:\\n        1. Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive.\\n2. Count the number of studio albums identified in this time period.\\n3. Record the final count as the answer.\\n\\nYou are tasked with executing step 1, Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive..', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HHoUWbV1r4s5vNya2U3i3faN', 'function': {'arguments': '{\"query\":\"Mercedes Sosa studio albums 2000 to 2009\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 280, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZJp8g00nvsfJ6yR0ak9R3ldLZP', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--0f18280f-02df-4185-ba62-edee2d9d4698-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa studio albums 2000 to 2009'}, 'id': 'call_HHoUWbV1r4s5vNya2U3i3faN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 280, 'output_tokens': 29, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='DISCOGRAFÍA DE MERCEDES SOSA - ORDEN CRONOLÓGICO DESCENDENTE - Cancioneros.com, canción de autor, ... Deja la vida volar, en gira (Mercedes Sosa) [EN SOLITARIO] 2009 Yo vengo a ofrecer mi corazón (Anna Saeki) [COLABORACIONES] ... (Mercedes Sosa) [2000] 2: Mujeres argentinas (Mercedes Sosa) [1969] 3: 30 años Listen to music from Mercedes Sosa like Alfonsina Y El Mar, Todo cambia & more. Find the latest tracks, albums, and images from Mercedes Sosa. Listen to your favorite songs from Mercedes Sosa. Stream ad-free with Amazon Music Unlimited on mobile, desktop, and tablet. Download our mobile app now. ... Album • 2009. 4. Lucerito. Album • 2015. 5. Mercedes Sosa En Argentina (En Directo) Album • 1982. 6. Cantora. Album • 2009. 7. 20 Éxitos de \"La voz de América\" 2000: Joan Baez \"Gracias a la Vida\" ... Mercedes Sosa received several Latin Grammy awards, including the award for Best Folk Album, acknowledging her significant contributions to Latin American music. Where did Mercedes Sosa perform a significant concert in 2009? Mercedes Sosa performed a significant concert in Buenos Aires in 2009, which ... A mediados de 2009, Mercedes Sosa editó el que sería el último disco de su vida: Cantora II, el segundo volumen de duetos que realizó con 35 artistas nacionales e internacionales. En el disco, la tucumana hizo dúo con Gustavo Cerati en \"Zona de promesas\". Ese mismo año, la cantante moriría, y meses después, en mayo de 2010, Cerati ...', name='duckduckgo_search', tool_call_id='call_HHoUWbV1r4s5vNya2U3i3faN'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KFLhEsMdc6m2ErvvCl69sHMm', 'function': {'arguments': '{\"query\":\"Mercedes Sosa studio albums list\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 712, 'total_tokens': 735, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZKKRiRpRiShQLq9POhGs8nDkE4', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--0c9cf9ee-e931-4d70-bff0-3106172a785d-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa studio albums list'}, 'id': 'call_KFLhEsMdc6m2ErvvCl69sHMm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 712, 'output_tokens': 23, 'total_tokens': 735, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==== CALLING ASSISTANT with 6 messages in queue\n",
      ">>>>> assistant_messages=[SystemMessage(content=[{'type': 'text', 'text': '\\n        You are an AI assistant anwering complex questions.\\n        Think step by step and answer following question.\\n        When doing web search, be very specific and precise with your queries and specify all the details - language, year, etc.\\n        Include all collected information into your response. '}], additional_kwargs={}, response_metadata={}), HumanMessage(content='For the following plan:\\n        1. Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive.\\n2. Count the number of studio albums identified in this time period.\\n3. Record the final count as the answer.\\n\\nYou are tasked with executing step 1, Identify and list all studio albums released by Mercedes Sosa between 2000 and 2009, inclusive..', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HHoUWbV1r4s5vNya2U3i3faN', 'function': {'arguments': '{\"query\":\"Mercedes Sosa studio albums 2000 to 2009\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 280, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZJp8g00nvsfJ6yR0ak9R3ldLZP', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--0f18280f-02df-4185-ba62-edee2d9d4698-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa studio albums 2000 to 2009'}, 'id': 'call_HHoUWbV1r4s5vNya2U3i3faN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 280, 'output_tokens': 29, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='DISCOGRAFÍA DE MERCEDES SOSA - ORDEN CRONOLÓGICO DESCENDENTE - Cancioneros.com, canción de autor, ... Deja la vida volar, en gira (Mercedes Sosa) [EN SOLITARIO] 2009 Yo vengo a ofrecer mi corazón (Anna Saeki) [COLABORACIONES] ... (Mercedes Sosa) [2000] 2: Mujeres argentinas (Mercedes Sosa) [1969] 3: 30 años Listen to music from Mercedes Sosa like Alfonsina Y El Mar, Todo cambia & more. Find the latest tracks, albums, and images from Mercedes Sosa. Listen to your favorite songs from Mercedes Sosa. Stream ad-free with Amazon Music Unlimited on mobile, desktop, and tablet. Download our mobile app now. ... Album • 2009. 4. Lucerito. Album • 2015. 5. Mercedes Sosa En Argentina (En Directo) Album • 1982. 6. Cantora. Album • 2009. 7. 20 Éxitos de \"La voz de América\" 2000: Joan Baez \"Gracias a la Vida\" ... Mercedes Sosa received several Latin Grammy awards, including the award for Best Folk Album, acknowledging her significant contributions to Latin American music. Where did Mercedes Sosa perform a significant concert in 2009? Mercedes Sosa performed a significant concert in Buenos Aires in 2009, which ... A mediados de 2009, Mercedes Sosa editó el que sería el último disco de su vida: Cantora II, el segundo volumen de duetos que realizó con 35 artistas nacionales e internacionales. En el disco, la tucumana hizo dúo con Gustavo Cerati en \"Zona de promesas\". Ese mismo año, la cantante moriría, y meses después, en mayo de 2010, Cerati ...', name='duckduckgo_search', tool_call_id='call_HHoUWbV1r4s5vNya2U3i3faN'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KFLhEsMdc6m2ErvvCl69sHMm', 'function': {'arguments': '{\"query\":\"Mercedes Sosa studio albums list\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 712, 'total_tokens': 735, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZKKRiRpRiShQLq9POhGs8nDkE4', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--0c9cf9ee-e931-4d70-bff0-3106172a785d-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa studio albums list'}, 'id': 'call_KFLhEsMdc6m2ErvvCl69sHMm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 712, 'output_tokens': 23, 'total_tokens': 735, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Mercedes Sosa, Nueva York, 1974 (Mercedes Sosa) [2024] SINGLES Y EP Gracias a la vida / Te recuerdo Amanda (Mercedes Sosa) [1969] La diablera (Mercedes Sosa) [1971] Si se calla el cantor / Guitarra de medianoche (Mercedes Sosa - Horacio Guarany) [1973] Canción de lejos (Mercedes Sosa) [1974] Recital al cantor (Mercedes Sosa - Horacio Guarany ... Listen to your favorite songs from Mercedes Sosa. Stream ad-free with Amazon Music Unlimited on mobile, desktop, and tablet. Download our mobile app now. ... Top Albums. 1. 30 años. Album • 1994. 2. Mujeres Argentinas. Album • 1969. 3. Cantora. Album • 2009. 4. Lucerito. Album • 2015. 5. Mercedes Sosa En Argentina (En Directo) Listen to music from Mercedes Sosa like Alfonsina Y El Mar, Todo cambia & more. Find the latest tracks, albums, and images from Mercedes Sosa. Mercedes Sosa, often referred to as the \"voice of the voiceless,\" was an iconic Argentine singer and folk music legend. Born on July 9, 1935, in Tucumán, Argen ... An Admirable Discography. Throughout her career, Sosa recorded over 40 albums, leaving behind a rich and diverse discography. Her albums showcased her ability to delve into various ... Discover the most popular tracks from Mercedes Sosa on Spotify, the total stream count and the monthly listeners and followers evolution. Open main menu Artists Countries', name='duckduckgo_search', tool_call_id='call_KFLhEsMdc6m2ErvvCl69sHMm'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_963oBbnlDCh5lYdqRLmVotzh', 'function': {'arguments': '{\"query\":\"Mercedes Sosa studio albums 2000 to 2009 list\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 1097, 'total_tokens': 1127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c8225066ea', 'id': 'chatcmpl-BSqZMG6AibbJjdkkypqoGUtQnO0A7', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--e2c3927c-9532-40c9-9986-3094cf052f65-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Mercedes Sosa studio albums 2000 to 2009 list'}, 'id': 'call_963oBbnlDCh5lYdqRLmVotzh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1097, 'output_tokens': 30, 'total_tokens': 1127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==== CALLING ASSISTANT with 8 messages in queue\n",
      "Other error, skipping question\n",
      "Error details: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'AnswerValidation': In context=('properties', 'answer_validation'), 'minItems' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "No answer produced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaros\\Documents\\Python\\hf_agents_course_final\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:407: UserWarning: Invalid schema for OpenAI's structured output feature, which is the default method for `with_structured_output` as of langchain-openai==0.3. Specify `method=\"function_calling\"` instead or update your schema. See supported schemas: https://platform.openai.com/docs/guides/structured-outputs#supported-schemas\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "question_generator = get_question(random=False)\n",
    "\n",
    "for question, task_id, file_name in question_generator:\n",
    "\n",
    "    answers_payload = []\n",
    "\n",
    "    print(\"Task ID:\", task_id)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"File Name:\", file_name or \"No file\")\n",
    "\n",
    "    file_content = None\n",
    "    file_type = None\n",
    "    if file_name:\n",
    "        file_type, file_content = read_file(file_name)\n",
    "\n",
    "    task_answer = None\n",
    "\n",
    "    # Try 3 times\n",
    "    for i in range(1):\n",
    "        try:\n",
    "            task_answer = compiled_graph.invoke(\n",
    "                {\n",
    "                    \"question\": question,\n",
    "                    \"task_id\": \"1\",\n",
    "                    \"file_name\": file_name,\n",
    "                    \"file_type\": file_type,\n",
    "                    \"file_content\": file_content,\n",
    "                    \"answer\": \"\",\n",
    "                    \"messages\": [],\n",
    "                    \"assistant_messages\": []\n",
    "                },\n",
    "                {\"recursion_limit\": 30},\n",
    "            )\n",
    "        except GraphRecursionError as e:\n",
    "            print(\"Recursion error, trying again...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(\"Other error, skipping question\\nError details:\", e)\n",
    "            break\n",
    "        break\n",
    "\n",
    "    if task_answer:\n",
    "        print(\"Answer:\", task_answer[\"answer\"])\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # answers_payload.append({\"task_id\": task_id, \"submitted_answer\": task_answer[\"answer\"]})\n",
    "        answers_payload = [{\"task_id\": task_id, \"submitted_answer\": task_answer[\"answer\"]}]\n",
    "\n",
    "        # TODO: Copy the final implementation to a Hugging Face space\n",
    "        submission_data = {\"username\": \"jarisko\", \"agent_code\": \"https://github.com/jarisko1/hf_agents_course_final\", \"answers\": answers_payload}\n",
    "\n",
    "        final_status = submit_answer(submission_data)\n",
    "        print(final_status)\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "    else:\n",
    "        print(\"No answer produced\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ffb14",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb47d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2db0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\"L1vXCYZAYYM\", add_video_info=False)\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41536c",
   "metadata": {},
   "source": [
    "# Test prebuilt agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac0a2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tools = [TavilySearchResults(max_results=3)]\n",
    "\n",
    "assistant_model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=\"gpt-4.1\",\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "prompt = \"You are a helpful assistant.\"\n",
    "agent_executor = create_react_agent(assistant_model, tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d18121f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Given this table defining * on the set S = {a, b, c, d, e}\\n\\n|*|a|b|c|d|e|\\n|---|---|---|---|---|---|\\n|a|a|b|c|b|d|\\n|b|b|c|a|e|c|\\n|c|c|a|b|b|a|\\n|d|b|e|b|e|d|\\n|e|d|b|a|d|c|\\n\\nprovide the subset of S involved in any possible counter-examples that prove * is not commutative. Provide your answer as a comma separated list of the elements in the set in alphabetical order.\\n', additional_kwargs={}, response_metadata={}, id='a92f0617-cf57-456d-b2cd-8fff979d5f5b'),\n",
       "  AIMessage(content=\"To determine if the operation * is not commutative on the set \\\\( S = \\\\{a, b, c, d, e\\\\} \\\\), we look for any pair \\\\((x, y)\\\\) such that \\\\(x * y \\\\neq y * x\\\\).\\n\\nLet's check for counter-examples by comparing each \\\\(x * y\\\\) with \\\\(y * x\\\\):\\n\\n### Step-by-step:\\n\\n- \\\\(a*b = b\\\\), \\\\(b*a = b\\\\) (equal)\\n- \\\\(a*c = c\\\\), \\\\(c*a = c\\\\) (equal)\\n- \\\\(a*d = b\\\\), \\\\(d*a = b\\\\) (equal)\\n- \\\\(a*e = d\\\\), \\\\(e*a = d\\\\) (equal)\\n- \\\\(b*c = a\\\\), \\\\(c*b = a\\\\) (equal)\\n- \\\\(b*d = e\\\\), \\\\(d*b = e\\\\) (equal)\\n- \\\\(b*e = c\\\\), \\\\(e*b = b\\\\) (**not equal!**: \\\\(c \\\\neq b\\\\))\\n- \\\\(c*d = b\\\\), \\\\(d*c = b\\\\) (equal)\\n- \\\\(c*e = a\\\\), \\\\(e*c = a\\\\) (equal)\\n- \\\\(d*e = d\\\\), \\\\(e*d = d\\\\) (equal)\\n\\nSo the only counter-example is \\\\(b*e = c\\\\) and \\\\(e*b = b\\\\). Thus, commutativity fails for \\\\(b\\\\) and \\\\(e\\\\), and also involves the result \\\\(c\\\\).\\n\\n### Subset involved in the counter-example(s):\\n\\nThe subset is the set of elements involved in any non-commutative outcome: \\\\(b\\\\), \\\\(c\\\\), and \\\\(e\\\\).\\n\\n**Answer:**  \\nb,c,e\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 374, 'prompt_tokens': 236, 'total_tokens': 610, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3dfb47c1f3', 'id': 'chatcmpl-BR0cExvHFHADZCOV0BhgaBoS4Tg6w', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-50424a6a-7270-4be6-9427-2c6ee2711cd0-0', usage_metadata={'input_tokens': 236, 'output_tokens': 374, 'total_tokens': 610, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [(\"user\", \"\"\"Given this table defining * on the set S = {a, b, c, d, e}\n",
    "\n",
    "|*|a|b|c|d|e|\n",
    "|---|---|---|---|---|---|\n",
    "|a|a|b|c|b|d|\n",
    "|b|b|c|a|e|c|\n",
    "|c|c|a|b|b|a|\n",
    "|d|b|e|b|e|d|\n",
    "|e|d|b|a|d|c|\n",
    "\n",
    "provide the subset of S involved in any possible counter-examples that prove * is not commutative. Provide your answer as a comma separated list of the elements in the set in alphabetical order.\n",
    "\"\"\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a18ed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "answers_payload = [{\"task_id\": \"6f37996b-2ac7-44b0-8e68-6d28256631b4\", \"submitted_answer\": \"b,c,e\"}]\n",
    "submission_data = {\"username\": \"jarisko\", \"agent_code\": \"https://github.com/jarisko1/hf_agents_course_final\", \"answers\": answers_payload}\n",
    "final_status = submit_answer(submission_data)\n",
    "print(final_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=[\"Go to the 'Featured Articles' log for English Wikipedia (https://en.wikipedia.org/wiki/Wikipedia:Featured_article_candidates/Featured_log).\", 'Find the section for November 2016 to see which articles were promoted that month.', 'For each article promoted in November 2016, look at the article topic/title to identify which one is about a dinosaur.', 'Once the dinosaur article is found, click through to its Featured Article Candidate (FAC) nomination page (linked from the log or via article talk page FA star).', 'On the FAC page, check the nomination statement for the user who nominated the article (their signature is usually at the top).', \"The nominator's username is the answer.\"])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
